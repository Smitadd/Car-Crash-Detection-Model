# Car-Crash-Detection-Model
The data set contains approximately 8,000 records. Each record represents a customer at an auto insurance company. The target variable (i.e., response variable) is TARGET_FLAG. It is either 1 or 0. A 1 means that the person was in a car crash. A 0 means that the person was not in a car crash.
Model Creation- Picked  models  like logistic regression, random forests, and bagging to make a comparison through accuracy rates with different svm classifier models. Got a Bagging accuracy of 79%, and random forest accuracy of 78%.Although for decision trees and random forest, I had to split the data further into x_train and X-validate to avoid overfitting on decision tree and random forest, the SVM model's accuracy was still better without being further split. The SVM model supports binary classification and separates data points into 2 classes.  Logistic regression model -accuracy of 80%  Accuracy = (917 + 5535) / (917 + 5535 + 1236 + 473) = 0.8007.When making a comparison between the logistic regression model and SVM with poly kernel the logistic gave a little higher accuracy. But, still, i’ll prefer svm poly because it tries to find the best margin that separates the classes and reduces the risk of error on the data.
The SVM model with RBF kernel gave an accuracy of 88% because the RBF kernel can transform the data points as much as possible for fitting the hyperplane between 2 classes of data points. Accuracy = (5936 + 1416) / (5936 + 737 + 72 + 1416). SVM classifier with RBF kernel gave the best accuracy as it uses gamma and c parameters that can be used to train the most optimal svm model using RBF 
SVM with LINEAR carnal gave the lowest Accuracy of 59%. We got low accuracy herein because if the data isn’t linearly separable then it’s impossible to classify the data 
SVM WITH POLYNOMIAL gave an ACCURACY of 78%
